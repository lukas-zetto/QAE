{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f593741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows: 551\n",
      "Ground truth anomalous windows: 55\n",
      "\n",
      "\n",
      "=== Evaluating file results/SMD\\ensemble_res_1.pkl (Run 1) ===\n",
      "Detected 15 anomalous windows above 90.02th percentile (threshold ≈ 0.8874)\n",
      "True Positives: 0\n",
      "False Positives: 15\n",
      "False Negatives: 55\n",
      "Precision: 0.00%\n",
      "Recall: 0.00%\n",
      "F1 Score: 0.00%\n",
      "Saved to evaluations/SMD/results_w1.txt\n",
      "\n",
      "=== Evaluating file results/SMD\\ensemble_res_2.pkl (Run 2) ===\n",
      "Detected 15 anomalous windows above 90.02th percentile (threshold ≈ 0.9099)\n",
      "True Positives: 0\n",
      "False Positives: 15\n",
      "False Negatives: 55\n",
      "Precision: 0.00%\n",
      "Recall: 0.00%\n",
      "F1 Score: 0.00%\n",
      "Saved to evaluations/SMD/results_w2.txt\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Settings for SMD ---\n",
    "window_size = 100     # SMD window size\n",
    "stride = 50           # SMD stride\n",
    "Ttotal = 27600        # total length in samples (longer than last anomaly)\n",
    "\n",
    "# --- Anomalous ranges (ground truth for SMD) ---\n",
    "anomalies = [\n",
    "    (16964, 17515),\n",
    "    (18072, 18528),\n",
    "    (19368, 20088),\n",
    "    (20787, 21195),\n",
    "    (24680, 24682),\n",
    "    (26115, 26116),\n",
    "    (27555, 27556),\n",
    "]\n",
    "\n",
    "total_windows = (Ttotal - window_size) // stride + 1\n",
    "\n",
    "# --- Ground truth anomalous windows ---\n",
    "start_times = [i * stride for i in range(total_windows)]\n",
    "anomalous_indices = set()\n",
    "for idx, start in enumerate(start_times):\n",
    "    end = start + window_size\n",
    "    for Astart, Aend in anomalies:\n",
    "        if min(end, Aend) > max(start, Astart):  # overlap check\n",
    "            anomalous_indices.add(idx)\n",
    "\n",
    "print(f\"Total windows: {total_windows}\")\n",
    "print(f\"Ground truth anomalous windows: {len(anomalous_indices)}\\n\")\n",
    "\n",
    "# --- Loop over all result files automatically ---\n",
    "result_files = glob.glob(\"results/SMD/ensemble_res_*.pkl\")\n",
    "\n",
    "for file in result_files:\n",
    "    x = os.path.splitext(os.path.basename(file))[0].split(\"_\")[-1]\n",
    "\n",
    "    print(f\"\\n=== Evaluating file {file} (Run {x}) ===\")\n",
    "\n",
    "    with open(file, \"rb\") as f:\n",
    "        all_results = pickle.load(f)\n",
    "\n",
    "    # --- Compute anomaly scores ---\n",
    "    anomaly_scores = defaultdict(lambda: {'score_sum': 0.0, 'count': 0})\n",
    "\n",
    "    for iteration_result in all_results:\n",
    "        buckets = iteration_result['buckets']\n",
    "        bucket_results = iteration_result['bucket_results']\n",
    "\n",
    "        for bucket_result in bucket_results:\n",
    "            bucket_idx = bucket_result['bucket_idx']\n",
    "            final_results = bucket_result['final_results']\n",
    "            indices_in_bucket = buckets[bucket_idx]\n",
    "\n",
    "            mean = np.mean(final_results)\n",
    "            std = np.std(final_results) if np.std(final_results) != 0 else 1e-8\n",
    "\n",
    "            for i, idx in enumerate(indices_in_bucket):\n",
    "                sim = final_results[i]\n",
    "                deviation = abs(sim - mean) / std\n",
    "                anomaly_scores[idx]['score_sum'] += deviation\n",
    "                anomaly_scores[idx]['count'] += 1\n",
    "\n",
    "    final_scores = {\n",
    "        idx: score_data['score_sum'] / score_data['count']\n",
    "        for idx, score_data in anomaly_scores.items()\n",
    "    }\n",
    "\n",
    "    # --- Percentile threshold based on anomaly ratio ---\n",
    "    true_anomaly_count = len(anomalous_indices)\n",
    "    PERCENTILE = 100 - (true_anomaly_count / total_windows) * 100\n",
    "    all_score_values = list(final_scores.values())\n",
    "    threshold = np.percentile(all_score_values, PERCENTILE)\n",
    "\n",
    "    # --- Detected anomalous windows ---\n",
    "    detected_windows = {\n",
    "        idx: score for idx, score in final_scores.items() if score >= threshold\n",
    "    }\n",
    "    detected_indices = set(detected_windows.keys())\n",
    "\n",
    "    # --- Metrics ---\n",
    "    true_positives = len(detected_indices & anomalous_indices)\n",
    "    false_positives = len(detected_indices - anomalous_indices)\n",
    "    false_negatives = len(anomalous_indices - detected_indices)\n",
    "\n",
    "    precision = true_positives / len(detected_indices) * 100 if detected_indices else 0\n",
    "    recall = true_positives / len(anomalous_indices) * 100 if anomalous_indices else 0\n",
    "    f1_score = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0\n",
    "\n",
    "    print(f\"Detected {len(detected_windows)} anomalous windows above {PERCENTILE:.2f}th percentile (threshold ≈ {threshold:.4f})\")\n",
    "    print(f\"True Positives: {true_positives}\")\n",
    "    print(f\"False Positives: {false_positives}\")\n",
    "    print(f\"False Negatives: {false_negatives}\")\n",
    "    print(f\"Precision: {precision:.2f}%\")\n",
    "    print(f\"Recall: {recall:.2f}%\")\n",
    "    print(f\"F1 Score: {f1_score:.2f}%\")\n",
    "\n",
    "    # --- Save results ---\n",
    "    output_dir = \"evaluations/SMD/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_filename = f\"results_w{x}.txt\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        for idx, score in sorted(detected_windows.items()):\n",
    "            f.write(f\"Window {idx} - Score: {score:.4f}\\n\")\n",
    "        f.write(f\"\\nTrue Positives: {true_positives}\")\n",
    "        f.write(f\"\\nFalse Positives: {false_positives}\")\n",
    "        f.write(f\"\\nFalse Negatives: {false_negatives}\")\n",
    "        f.write(f\"\\nPrecision: {precision:.2f}%\")\n",
    "        f.write(f\"\\nRecall: {recall:.2f}%\")\n",
    "        f.write(f\"\\nF1 Score: {f1_score:.2f}%\")\n",
    "\n",
    "    print(f\"Saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
